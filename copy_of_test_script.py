# -*- coding: utf-8 -*-
"""Copy of test_script.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nkJMMm2unCTtprOZ6IXEi4ae__uggj8-
"""

#!pip install joblib numpy scipy pandas scikit-learn

import numpy as np
import joblib
from scipy import stats
from scipy.stats import entropy
import pandas as pd

def generate_simulated_sensor_data(samples=1000):
    """Generate simulated sensor data for testing"""
    accel_data = np.random.normal(0, 1, samples) + 0.1 * np.sin(np.linspace(0, 10, samples))
    vib_data   = np.random.normal(0, 0.5, samples) + 0.05 * np.cos(np.linspace(0, 15, samples))
    return accel_data, vib_data

def _safe_entropy(x, bins=10):
    hist, _ = np.histogram(x, bins=bins)
    p = hist.astype(float)
    s = p.sum()
    if s == 0:
        return 0.0
    p = p / s
    return float(entropy(p + 1e-12, base=np.e))

def extract_features(sensor_data):
    features = {}
    features['mean']     = float(np.mean(sensor_data))
    features['rms']      = float(np.sqrt(np.mean(sensor_data**2)))
    features['peak']     = float(np.max(np.abs(sensor_data)))
    features['std']      = float(np.std(sensor_data))
    features['kurtosis'] = float(stats.kurtosis(sensor_data))
    features['skew']     = float(stats.skew(sensor_data))
    features['crest']    = float(features['peak'] / features['rms']) if features['rms'] != 0 else 0.0
    features['entropy']  = _safe_entropy(sensor_data, bins=10)
    return [
        features['mean'], features['rms'], features['peak'], features['std'],
        features['kurtosis'], features['skew'], features['crest'], features['entropy']
    ]

def create_nasa_compatible_features(accel_features, vib_features):
    """
    Create features that match the model's expected 96 features:
    Sensors: B1_x, B1_y, ..., B4_y
    For each sensor (12 features): mean, std, skew, kurtosis, entropy, rms, max, p2p, crest, clearence, shape, impulse
    """
    time_features = ['mean', 'std', 'skew', 'kurtosis', 'entropy', 'rms',
                     'max', 'p2p', 'crest', 'clearence', 'shape', 'impulse']
    sensors = ['B1_x', 'B1_y', 'B2_x', 'B2_y', 'B3_x', 'B3_y', 'B4_x', 'B4_y']

    feature_names = [f"{s}_{t}" for s in sensors for t in time_features]
    feature_values = []

    for i, sensor in enumerate(sensors):
        source = accel_features if (i % 2 == 0) else vib_features  # x->accel, y->vib
        mapped = [
            source[0],          # mean
            source[3],          # std
            source[5],          # skew
            source[4],          # kurtosis
            source[7],          # entropy
            source[1],          # rms
            source[2],          # max (peak)
            source[2],          # p2p (approx with peak)
            source[6],          # crest
            source[6] * 0.8,    # clearence (approx)
            (source[1] / source[0]) if source[0] != 0 else 1.0,  # shape
            (source[2] / source[0]) if source[0] != 0 else 1.0,  # impulse
        ]
        feature_values.extend(mapped)

    feature_df = pd.DataFrame([feature_values], columns=feature_names)
    return feature_df

# Debug helpers
def debug_model_expectations():
    """Debug function to understand what the model expects"""
    try:
        predictor = joblib.load('smart_rul_predictor.pkl')

        if hasattr(predictor, 'feature_names_in_'):
            print("Model expected feature names:")
            print(list(predictor.feature_names_in_))

        if hasattr(predictor, 'scaler'):
            if hasattr(predictor.scaler, 'feature_names_in_'):
                print("Scaler expected features:")
                print(list(predictor.scaler.feature_names_in_))

        print("\nModel attributes:")
        for attr in dir(predictor):
            if not attr.startswith('_'):
                print(f"  {attr}")
    except Exception as e:
        print(f"Debug error: {e}")


class SmartRULPredictor:
    """
    Smart wrapper that converts predictions to appropriate time units.
    Accepts a pandas.DataFrame (preferred) or array-like.
    """
    def __init__(self, model, scaler, time_unit_minutes=10):
        self.model = model
        self.scaler = scaler
        self.time_unit_minutes = time_unit_minutes

    def _prepare_X(self, features):
        # If DataFrame: preserve names and align to scaler's training order
        if isinstance(features, pd.DataFrame):
            X = features.copy()
            if hasattr(self.scaler, "feature_names_in_"):
                expected = list(self.scaler.feature_names_in_)
                missing = [c for c in expected if c not in X.columns]
                extra   = [c for c in X.columns if c not in expected]
                if missing:
                    raise ValueError(f"Missing features for scaler: {missing[:8]}{'...' if len(missing)>8 else ''}")
                X = X[expected]  # reorder columns to match scaler fit order
            return X  # stays 2D
        # Else array-like
        X = np.asarray(features, dtype=float)
        if X.ndim == 1:
            X = X.reshape(1, -1)
        elif X.ndim > 2:
            raise ValueError(f"features has ndim={X.ndim}; expected 1D or 2D")
        return X

    def predict_rul_smart(self, features):
        # *** FIX: do NOT wrap features in [ ... ]; just prepare 2D ***
        X = self._prepare_X(features)
        scaled = self.scaler.transform(X)
        pred = self.model.predict(scaled)
        rul_units = float(pred[0])

        # Convert to hours from 'time_unit_minutes'
        rul_hours = rul_units * self.time_unit_minutes / 60.0

        if rul_hours >= 24 * 30:    return self._format_months(rul_hours)
        if rul_hours >= 24 * 7:     return self._format_weeks(rul_hours)
        if rul_hours >= 24:         return self._format_days(rul_hours)
        return self._format_hours(rul_hours)

    def _format_months(self, hours):
        months = int(hours // (24 * 30))
        days   = int((hours % (24 * 30)) // 24)
        return {"value": hours,
                "formatted": f"{months} month{'s' if months!=1 else ''}" + ("" if days==0 else f" {days} day{'s' if days!=1 else ''}"),
                "unit": "months", "months": months, "days": days}

    def _format_weeks(self, hours):
        weeks = int(hours // (24 * 7))
        days  = int((hours % (24 * 7)) // 24)
        return {"value": hours,
                "formatted": f"{weeks} week{'s' if weeks!=1 else ''}" + ("" if days==0 else f" {days} day{'s' if days!=1 else ''}"),
                "unit": "weeks", "weeks": weeks, "days": days}

    def _format_days(self, hours):
        days = int(hours // 24)
        rem  = int(hours % 24)
        return {"value": hours,
                "formatted": f"{days} day{'s' if days!=1 else ''}" + ("" if rem==0 else f" {rem} hour{'s' if rem!=1 else ''}"),
                "unit": "days", "days": days, "hours": rem}

    def _format_hours(self, hours):
        h = int(hours)
        m = int(round((hours - h) * 60))
        if m == 60:
            h += 1; m = 0
        return {"value": hours,
                "formatted": f"{h} hour{'s' if h!=1 else ''}" + ("" if m==0 else f" {m} minute{'s' if m!=1 else ''}"),
                "unit": "hours", "hours": h, "minutes": m}

def test_rul_prediction():
    try:
        print("=== Red Pitaya RUL Model Test ===")

        predictor = joblib.load('smart_rul_predictor.pkl')
        print("✓ Model loaded successfully")

        accel_data, vib_data = generate_simulated_sensor_data(1000)
        print("✓ Simulated sensor data generated")

        accel_features = extract_features(accel_data)
        vib_features   = extract_features(vib_data)
        print("✓ Features extracted")

        feature_df = create_nasa_compatible_features(accel_features, vib_features)
        print("✓ NASA-compatible feature DataFrame created")
        print(f"  Shape: {feature_df.shape}")
        print(f"  Expected: (1, 96), Got: {feature_df.shape}")

        # Optional sanity: check names against scaler
        if hasattr(predictor, "scaler") and hasattr(predictor.scaler, "feature_names_in_"):
            expected = set(predictor.scaler.feature_names_in_)
            got = set(feature_df.columns)
            print("  Missing:", list(expected - got)[:5])
            print("  Extra:", list(got - expected)[:5])

        # *** Pass DataFrame directly (no wrapping) ***
        prediction = predictor.predict_rul_smart(feature_df)
        print(f"✓ RUL Prediction: {prediction}")

        print("✓ Test completed successfully!")
        return True

    except Exception as e:
        print(f"❌ Error: {e}")
        print(f"Error type: {type(e).__name__}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("=== Model Debug Info ===")
    debug_model_expectations()
    print("\n" + "="*50 + "\n")
    test_rul_prediction()